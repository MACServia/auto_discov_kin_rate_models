"##############################################################################"
"######################## Importing important packages ########################"
"##############################################################################"

import numpy as np
from scipy.integrate import solve_ivp
import matplotlib.pyplot as plt
import pandas as pd
from pysr import PySRRegressor
from sympy import *
from scipy.misc import derivative as der
import re
from scipy.integrate import solve_ivp
import itertools as it 
from time import perf_counter
import matplotlib.cm as cm
from scipy.optimize import minimize
from beecolpy import abc
np.random.seed(1998)


"##############################################################################"
"####################### Synthetic data from case study #######################"
"##############################################################################"

# Case study
def kinetic_model(t, z):
    k_f = 7
    k_r = 3 
    k_A = 4 
    k_B = 2 
    k_C = 6 

    dAdt = (-k_f * z[0] + k_r * z[1]) / (k_A * z[0] + k_B * z[1] + k_C)
    dBdt = (-1) * (-k_f * z[0] + k_r * z[1]) / (k_A * z[0] + k_B * z[1] + k_C)

    dzdt = [dAdt, dBdt]
    return dzdt

# Plotting the data given
species = ["A", "B"]
initial_conditions = {
    "ic_1": np.array([2 , 0]),
    "ic_2": np.array([10, 0]),
    "ic_3": np.array([2 , 2]),
    "ic_4": np.array([10, 2]),
    "ic_5": np.array([10, 1]),

    "ic_6": np.array([7.319, 2.000])
}

num_exp = len(initial_conditions)
num_species = len(species)

timesteps = 30
time = np.linspace(0, 10, timesteps)
t = [0, np.max(time)]
t_eval = list(time)
STD = 0.2 
noise = [np.random.normal(0, STD, size = (num_species, timesteps)) for i in range(num_exp)]
in_silico_data = {}
no_noise_data = {}

for i in range(num_exp):
    ic = initial_conditions["ic_" + str(i + 1)]
    solution = solve_ivp(kinetic_model, t, ic, t_eval = t_eval, method = "RK45")
    in_silico_data["exp_" + str(i + 1)] = np.clip(solution.y + noise[i], 0, 1e99)
    no_noise_data["exp_" + str(i + 1)] = solution.y

color_1 = ['salmon', 'royalblue']
marker = ['o', '+', 'x', 'v']

# Plotting the in-silico data for visualisation
for i in range(num_exp):
    fig, ax = plt.subplots()
    ax.set_title("Experiment " + str(i + 1))
    ax.set_ylabel("Concentration $(M)$")
    ax.set_xlabel("Time $(h)$")
    ax.spines["right"].set_visible(False)
    ax.spines["top"].set_visible(False)

    for j in range(num_species):
        y = in_silico_data["exp_" + str(i + 1)][j]
        ax.plot(time, y, marker[j], markersize = 3, label = species[j], color = color_1[j])

    ax.grid(alpha = 0.5)
    ax.legend()
# plt.show()


"##############################################################################"
"############################ Find Best Rate Model ############################"
"##############################################################################"

# In this first part, we read the rate equations generated by symbolic regression
# And we pick the best equation for each species by evaluating them in the rate space
# Aka, we find the predicted rates and we compare with the estimated rates
# This is not the best way to do it, so essentially, ignore it
def rate_n_param(path):
    # read equations from CSV with different separator 
    data = pd.read_csv(path)
    # convert dataframe into numpy array
    eqs = data["Equation"].values
    x1, x2 = symbols("x1 x2")
    simple_traj = []
    param = []

    for eq in eqs:
        func = simplify(eq)
        func = str(func)
        j = 0
        things = re.findall(r"(\*{2}|\*{0})(\d+\.?\d*)", func)

        for i in range(len(things)):
            if things[i][0] != "**":
                j += 1
        
        simple_traj.append(func)
        param.append(int(j))
    # simple_traj = np.array(simple_traj).tolist()

    return simple_traj, param

rate_models = {}
GP_models = {}

path = "Synthetic Isomerisation/Second Paper Data/hall_of_fame_rate_ADoK-W_2.csv"
name_models = "rate_models"
name_params = "rate_params"

a, b = rate_n_param(path)
GP_models[name_models, name_params] = a, b

# In this second part, we read the symbolic expressions from the csv files, but now
# We make all possible combinations of ODEs from the proposed models and we evaluate
# Each of them and select the best one

# Here, we give make a function with a given ODE and we evaluated at a given initial condition
def rate_model(z0, equations, t, t_eval, event):
    i = 0

    for equation in equations:
        equation = str(equation)
        equation = equation.replace("x1", "z[0]")
        equation = equation.replace("x2", "z[1]")
        equations[i] = equation
        i += 1

    def nest(t, z):
        dAdt = (-1) * eval(str(equations[0]))
        dBdt = eval(str(equations[0]))
        dzdt = [dAdt, dBdt]
        return dzdt

    sol = solve_ivp(nest, t, z0, t_eval = t_eval, method = "RK45", events = event)  

    return sol.y, sol.t, sol.status

# Here we evaluate the NLL for a given ODE and experiment
def NLL_kinetics(experiments, predictions, number_species, number_datapoints):
    output = np.zeros(number_species)
    mse = np.zeros(number_species)
    variance = np.zeros(number_species)

    for i in range(number_species):
        a = ((experiments[i] - predictions[i])**2)
        mse[i] = np.sum(a)
        variance[i] = mse[i] / (number_datapoints)

    for i in range(number_species):
        likelihood = ((experiments[i] - predictions[i])**2) / (2 * (variance[i])) \
            - np.log(1 / (np.sqrt(2 * np.pi * (variance[i]))))
        output[i] = np.sum(likelihood)

    return np.sum(output)

# Part of solve_ivp syntax - to make sure if the ODE takes longer than 5 seconds to solve
# It gets assigned a big ol' penalty
def my_event(t, y):
    time_out = perf_counter()

    if (time_out - time_in) > 2:
        return 0

    else:
        return 1

my_event.terminal = True

# Here we make all the possible ODEs and save the number of parameters that exists in them
# Evaluate over all possible models and experiments, save the NLL for each ODE system
all_ODEs = GP_models["rate_models", "rate_params"][0]
params = GP_models["rate_models", "rate_params"][1]
number_models = len(all_ODEs)
all_ODEs = [[x] for x in all_ODEs]
AIC_values = np.zeros(number_models)

for i in range(number_models):
    neg_log = 0
    print(i)

    for j in range(num_exp):
        t = time
        experiments = in_silico_data["exp_" + str(j + 1)]
        time_in = perf_counter()
        ics = initial_conditions["ic_" + str(j + 1)]
        y, tt, status = rate_model(ics, list(all_ODEs[i]), [0, np.max(t)], list(t), my_event)

        if status == -1:
            neg_log = 1e99
            break

        elif status == 1:
            neg_log = 1e99
            break

        else:
            neg_log += NLL_kinetics(experiments, y, num_species, timesteps)

    # num_parameters = np.sum(np.array(param_ODEs[i]))
    num_parameters = np.sum(np.array(params[i]))
    print(neg_log)
    AIC_values[i] = 2 * neg_log + 2 * num_parameters

# Find the best model and plot it
best_model_index = np.argmin(AIC_values)
second_min_index = np.argpartition(AIC_values, 1)[1]

for i in range(num_exp):
    t = time
    time_in = perf_counter()
    ics = initial_conditions["ic_" + str(i + 1)]
    yy, tt, _ = rate_model(ics, list(all_ODEs[-1]), [0, np.max(t)], list(t), my_event)

    fig, ax = plt.subplots()
    ax.set_title("Experiment " + str(i + 1))
    ax.set_ylabel("Concentration $(M)$")
    ax.set_xlabel("Time $(h)$")

    for j in range(num_species):
        y = in_silico_data["exp_" + str(i + 1)][j]
        ax.plot(t, y, "x", markersize = 3, label = species[j], color = color_1[j])
        ax.plot(tt, yy[j], color = color_1[j])

    ax.spines["right"].set_visible(False)
    ax.spines["top"].set_visible(False) 
    ax.grid(alpha = 0.5)
    ax.legend()
# plt.show()

print(all_ODEs[best_model_index])
print(all_ODEs[second_min_index])

# data = pd.read_excel("test_data.xlsx")
# data = pd.DataFrame.to_numpy(data)
# data = np.delete(data, 0, axis = 1)
# test_noise = np.random.normal(0, 0.01, size = (timesteps, num_species))
# # test_noise = np.zeros((timesteps, num_species))
# test = (data + test_noise).T
# t = time
# time_in = perf_counter()
# ics = initial_conditions["ic_" + str(i + 1)][0]
# yy, tt, _ = rate_model(ics, list(all_ODEs[best_model_index]), [0, np.max(t)], list(t), my_event)

# fig, ax = plt.subplots()
# ax.set_title("Experiment " + str(i + 1))
# ax.set_ylabel("Concentrations $(M)$")
# ax.set_xlabel("Time $(s)$")

# for j in range(num_species):
#     y = in_silico_data["exp_" + str(i + 1)][j]
#     ax.plot(t, test[j], "x", markersize = 3, label = species[j], color = color_1[j])
#     ax.plot(tt, yy[j], color = color_1[j])

# ax.spines["right"].set_visible(False)
# ax.spines["top"].set_visible(False)
# ax.grid(alpha = 0.5)
# ax.legend()
# plt.show()


"##############################################################################"
"############################ Optimise Rate Model #############################"
"##############################################################################"

def competition(k, z0):
    k_1 = k[0]
    k_2 = k[1]
    k_3 = k[2]
    k_4 = k[3]
    k_5 = k[4]
    k_6 = k[5]

    def nest(t, z):
        dAdt = (-1) * ((k_1 * z[0] - k_2 * z[1] + k_3)/ (k_4 * z[0] + k_5 * z[1] + k_6))
        dBdt = ((k_1 * z[0] - k_2 * z[1] + k_3)/ (k_4 * z[0] + z[1] + k_5))
        dzdt = [dAdt, dBdt]
        return dzdt
    
    # time points
    time = np.linspace(0, 10, 30)
    t = [0, np.max(time)]
    t_eval = list(time)
    
    # solve ODE
    sol = solve_ivp(nest, t, z0, t_eval = t_eval, method = "RK45")
    
    return sol.y


def nll(params, model):
    num_exp = len(initial_conditions)

    for i in range(num_exp):
        ic = initial_conditions["ic_" + str(i+1)]
        observations = in_silico_data["exp_" + str(i + 1)]
        model_response = model(params, ic)

        SSE = (observations - model_response)**2
        shape_data = np.shape(in_silico_data["exp_" + str(i + 1)])
        num_species = shape_data[0]
        num_datapoints = shape_data[1]
        variance = np.sum(SSE) / (num_species * num_datapoints)

        placeholder = (SSE / (2 * variance)) - np.log(1 / (np.sqrt(2 * np.pi * (variance))))
        likelihood = np.sum(placeholder)

    return likelihood

def sse(params):
    num_exp = len(initial_conditions)
    total = np.zeros((num_exp, 1))

    for i in range(num_exp):
        ic = initial_conditions["ic_" + str(i+1)]
        observations = in_silico_data["exp_" + str(i + 1)]
        model_response = competition(params, ic)

        SSE = (observations - model_response)**2
        total[i] = np.sum(SSE)

    return np.sum(total)

# def callback(xk):
#     # Print out the current solution
#     print(f"Current solution: {xk}")

# def Opt_Rout(multistart, number_parameters, x0, lower_bound, upper_bound, to_opt):
#     localsol = np.empty([multistart, number_parameters])
#     localval = np.empty([multistart, 1])
#     boundss = tuple([(lower_bound, upper_bound) for i in range(number_parameters)])
    
#     for i in range(multistart):
#         res = minimize(to_opt, x0, method = 'L-BFGS-B', \
#                        bounds = boundss, callback = callback)
#         localsol[i] = res.x
#         localval[i] = res.fun

#     minindex = np.argmin(localval)
#     opt_val = localval[minindex]
#     opt_param = localsol[minindex]
    
#     return opt_val, opt_param

# multistart = 10
# number_parameters = 5
# lower_bound = 0.0001
# upper_bound = 10

# abc_obj = abc(sse, [(lower_bound, upper_bound) for i in range(number_parameters)])
# abc_obj.fit() 

# solution = abc_obj.get_solution()
# print('Initial guess = ', solution)

# opt_val, opt_param = Opt_Rout(multistart, number_parameters, solution, lower_bound, \
#     upper_bound, sse)

# print('SSE = ', opt_val)
# print('Optimal parameters = ', opt_param)

# for i in range(num_exp):
#     t = time
#     time_in = perf_counter()
#     ics = initial_conditions["ic_" + str(i + 1)]
#     yy = competition(opt_param, ics)

#     fig, ax = plt.subplots()
#     # ax.set_title("Experiment " + str(i + 1))
#     ax.set_ylabel("Concentration $(M)$")
#     ax.set_xlabel("Time $(h)$")

#     for j in range(num_species):
#         y = in_silico_data["exp_" + str(i + 1)][j]
#         ax.plot(t, y, "o", markersize = 3, label = species[j], color = color_1[j])
#         ax.plot(tt, yy[j], color = color_1[j])

#     ax.spines["right"].set_visible(False)
#     ax.spines["top"].set_visible(False)
#     ax.grid(alpha = 0.5)
#     ax.legend()
    
#     if i == 2:
#         file_path = 'Synthetic Isomerisation/Experiment_3_Final_Model_IsoW.png'
#         plt.savefig(file_path, dpi = 600)

# # plt.show()